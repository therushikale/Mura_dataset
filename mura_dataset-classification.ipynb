{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MURA DATASET visualization and preprocessing**\n",
    "\n",
    "\n",
    "NAME:RUSHIKESH KALE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>531</td>\n",
       "      <td>fracture</td>\n",
       "      <td>291</td>\n",
       "      <td>225</td>\n",
       "      <td>352</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.jpg</td>\n",
       "      <td>872</td>\n",
       "      <td>1024</td>\n",
       "      <td>fracture</td>\n",
       "      <td>578</td>\n",
       "      <td>202</td>\n",
       "      <td>675</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158.jpg</td>\n",
       "      <td>872</td>\n",
       "      <td>1024</td>\n",
       "      <td>fracture</td>\n",
       "      <td>570</td>\n",
       "      <td>67</td>\n",
       "      <td>609</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.jpg</td>\n",
       "      <td>1500</td>\n",
       "      <td>2000</td>\n",
       "      <td>fracture</td>\n",
       "      <td>715</td>\n",
       "      <td>1114</td>\n",
       "      <td>921</td>\n",
       "      <td>1405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.jpg</td>\n",
       "      <td>555</td>\n",
       "      <td>865</td>\n",
       "      <td>fracture</td>\n",
       "      <td>141</td>\n",
       "      <td>402</td>\n",
       "      <td>170</td>\n",
       "      <td>421</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>69.jpg</td>\n",
       "      <td>327</td>\n",
       "      <td>442</td>\n",
       "      <td>fracture</td>\n",
       "      <td>84</td>\n",
       "      <td>217</td>\n",
       "      <td>117</td>\n",
       "      <td>274</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>213.jpg</td>\n",
       "      <td>946</td>\n",
       "      <td>1500</td>\n",
       "      <td>fracture</td>\n",
       "      <td>285</td>\n",
       "      <td>781</td>\n",
       "      <td>378</td>\n",
       "      <td>899</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>213.jpg</td>\n",
       "      <td>946</td>\n",
       "      <td>1500</td>\n",
       "      <td>fracture</td>\n",
       "      <td>376</td>\n",
       "      <td>746</td>\n",
       "      <td>469</td>\n",
       "      <td>869</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>234.jpg</td>\n",
       "      <td>525</td>\n",
       "      <td>812</td>\n",
       "      <td>fracture</td>\n",
       "      <td>400</td>\n",
       "      <td>384</td>\n",
       "      <td>446</td>\n",
       "      <td>431</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>89.jpg</td>\n",
       "      <td>1754</td>\n",
       "      <td>2333</td>\n",
       "      <td>fracture</td>\n",
       "      <td>1339</td>\n",
       "      <td>1366</td>\n",
       "      <td>1500</td>\n",
       "      <td>1538</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  width  height     class  xmin  ymin  xmax  ymax  image_id\n",
       "0     10.jpg    800     531  fracture   291   225   352   309         0\n",
       "1    158.jpg    872    1024  fracture   578   202   675   349         1\n",
       "2    158.jpg    872    1024  fracture   570    67   609   132         1\n",
       "3     37.jpg   1500    2000  fracture   715  1114   921  1405         2\n",
       "4     87.jpg    555     865  fracture   141   402   170   421         3\n",
       "..       ...    ...     ...       ...   ...   ...   ...   ...       ...\n",
       "288   69.jpg    327     442  fracture    84   217   117   274       233\n",
       "289  213.jpg    946    1500  fracture   285   781   378   899       234\n",
       "290  213.jpg    946    1500  fracture   376   746   469   869       234\n",
       "291  234.jpg    525     812  fracture   400   384   446   431       235\n",
       "292   89.jpg   1754    2333  fracture  1339  1366  1500  1538       236\n",
       "\n",
       "[293 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_paths = pd.read_csv('train.csv')\n",
    "train_images_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 9 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11216/871756007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_images_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_images_paths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'http://localhost:8888/view/test/1.jpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_images_paths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5498\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5499\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5501\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5502\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 9 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "train_images_paths = pd.read_csv('train.csv')\n",
    "train_images_paths.columns = ['http://localhost:8888/view/test/1.jpg']\n",
    "train_images_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images_paths['label'] = train_images_paths['image_path'].map(lambda x:'positive' if 'positive' in x else 'negative')\n",
    "train_images_paths['category']  = train_images_paths['image_path'].apply(lambda x: x.split('/')[2])  \n",
    "train_images_paths['patientId']  = train_images_paths['image_path'].apply(lambda x: x.split('/')[3].replace('patient',''))\n",
    "train_images_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_training_images = np.shape(train_images_paths)[0]\n",
    "print(\"total number of images:\",total_number_of_training_images )\n",
    "print (\"\\n\\nnumber of null values\", train_images_paths.isnull().sum())\n",
    "print(\"\\n\\nnumber of training images:\",np.shape(train_images_paths['image_path'])[0])\n",
    "categories_counts = pd.DataFrame(train_images_paths['category'].value_counts())\n",
    "print ('\\n\\ncategories:\\n',categories_counts )\n",
    "print('\\n\\nnumber of patients:',train_images_paths['patientId'].nunique())\n",
    "print('\\n\\nnumber of labels:',train_images_paths['label'].nunique())\n",
    "print ('\\n\\npositive casses:',len(train_images_paths[train_images_paths['label']=='positive']))\n",
    "print ('\\n\\nnegative casses:',len(train_images_paths[train_images_paths['label']=='negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_paths_csv = \"valid_image_paths.csv\"\n",
    "valid_data_paths = pd.read_csv(os.path.join(path,valid_image_paths_csv),dtype=str,header=None)\n",
    "valid_data_paths.columns = ['image_path']\n",
    "print (valid_data_paths.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_paths['label'] = valid_data_paths['image_path'].map(lambda x:'positive' if 'positive' in x else 'negative')\n",
    "valid_data_paths['category']  = valid_data_paths['image_path'].apply(lambda x: x.split('/')[2])  \n",
    "valid_data_paths['dir'] =  valid_data_paths['image_path'].apply(lambda x: x.split('/')[1])\n",
    "valid_data_paths['patientId']  = valid_data_paths['image_path'].apply(lambda x: x.split('/')[3].replace('patient',''))\n",
    "valid_data_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data_shape:\",np.shape(valid_data_paths))\n",
    "print (\"\\n\\nnumber of null values\", valid_data_paths.isnull().sum())\n",
    "print(\"\\n\\nnumber of training images:\",np.shape(valid_data_paths['image_path']))\n",
    "\n",
    "validaton_categories_counts = pd.DataFrame(valid_data_paths['category'].value_counts())\n",
    "print ('\\n\\ncategories:\\n',validaton_categories_counts)\n",
    "print('\\n\\nnumber of patients:',valid_data_paths['patientId'].nunique())\n",
    "print('\\n\\nnumber of labels:',valid_data_paths['label'].nunique())\n",
    "print ('\\n\\npositive casses:',len(valid_data_paths[valid_data_paths['label']=='positive']))\n",
    "print ('\\n\\nnegative casses:',len(valid_data_paths[valid_data_paths['label']=='negative']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d1bff1d-a494-4c11-86d4-2aabc185abc2",
    "_uuid": "c0b5f85eedfd3ddeee3b7faaaa617e8cfa4e4d7c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "63d5876d-d81b-4cff-80b1-d5048a8ce817",
    "_uuid": "c29a0c3ec6519a003dd2fe1922187e6a98e674ef"
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg_train_settings = dict(samplewise_center = True,\n",
    "                         samplewise_std_normalization = True,\n",
    "                          rotation_range = 5, \n",
    "                          width_shift_range = 0.1, \n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1, \n",
    "                         horizontal_flip = True,\n",
    "                         vertical_flip = True)\n",
    "idg_train = ImageDataGenerator(**idg_train_settings)\n",
    "\n",
    "idg_valid_settings = dict(samplewise_center = True,\n",
    "                         samplewise_std_normalization = True,\n",
    "                          rotation_range = 0, \n",
    "                          width_shift_range = 0., \n",
    "                         height_shift_range = 0.,\n",
    "                         zoom_range = 0.0, \n",
    "                         horizontal_flip = False,\n",
    "                         vertical_flip = False)\n",
    "idg_valid = ImageDataGenerator(**idg_valid_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in train_df_of_cat all train_images_paths if you want to train on all dataset\n",
    "# we will choose category which is not too much images or too many \n",
    "# XR_ELBOW or XR_FINGER both have some moderate nomber of examples \n",
    "# for train only on XR_ELBOW category we use this mask\n",
    "category = 'XR_WRIST'\n",
    "train_mask = train_images_paths['category'] == category\n",
    "valid_mask = valid_data_paths['category']==category\n",
    "train_df_of_cat = train_images_paths\n",
    "valid_df_of_cat = valid_data_paths\n",
    "train_df_of_cat['label'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data for training \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "258c6ecb-119b-4d54-858b-ff6e9dbde89e",
    "_uuid": "2f5770d1f8c8a29008b71ef3379d4ed5a06c6ca8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "images_path_dir = \"../input/mura-v11\"\n",
    "out_dir = \"./\"\n",
    "\n",
    "train_generator = idg_train.flow_from_dataframe(\n",
    "    dataframe = train_df_of_cat,\n",
    "    directory = images_path_dir,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (128, 128),\n",
    "    save_to_dir = out_dir,\n",
    "    save_format = \"png\",\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "valid_generator = idg_valid.flow_from_dataframe(\n",
    "    dataframe = valid_df_of_cat,\n",
    "    directory = images_path_dir,\n",
    "    x_col = 'image_path',\n",
    "    y_col = 'label',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (128, 128),\n",
    "    save_to_dir = out_dir,\n",
    "    save_format = \"png\",\n",
    "    color_mode = 'grayscale')\n",
    "\n",
    "STEP_SIZE_TRAIN=math.ceil(train_generator.n / train_generator.batch_size)\n",
    "STEP_SIZE_VALID=math.ceil(valid_generator.n / valid_generator.batch_size)\n",
    "\n",
    "a, b = next(train_generator)\n",
    "i,l = next(valid_generator)\n",
    "print(\"training input images patch shape  : \", a.shape)\n",
    "print(\"training input labels patch shape  : \",b.shape)\n",
    "print(\"training labels:\",train_generator.class_indices)\n",
    "print (\"________________________________________\")\n",
    "print(\"validation input images patch shape: \", a.shape)\n",
    "print(\"validation input labels patch shape: \",b.shape)\n",
    "print(\"validation labels:\",valid_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68e5554b-d56e-4567-a0ee-992f9d419baa",
    "_uuid": "12bc23f900027dbebd400ac3970155839289187b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape =a.shape[1:]\n",
    "classes = b.shape[1] #binary classification normal vs upnormal \n",
    "loss_func = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "epochs = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e5f82e2-6125-4260-a363-3f7c5b681db8",
    "_uuid": "b691c2b0665f19eaa4fe52bd5235addb8058dae1"
   },
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "model = MobileNet(classes=classes,dropout=0.01, weights = None, input_shape=input_shape)\n",
    "model.compile(optimizer=optimizer, loss=loss_func, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f87714bc-4d90-48c7-97a5-ac80a942a39e",
    "_uuid": "2bafd9e1f576e3f9c5aecfc2d8c9323adb5ca98e"
   },
   "outputs": [],
   "source": [
    "print('Layers: {}, parameters: {}'.format(len(model.layers), model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bbd6c9ad-1f3c-41dd-adbd-ec58f93d5fe7",
    "_uuid": "7a303496021cd54f5e99c0b2a3bd6e53bd533013"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "file_path=category+\"_MobileNet_weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(os.path.join(out_dir,file_path),\n",
    "                                monitor='val_loss',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True,\n",
    "                                mode='min')\n",
    "#                              monitor='val_loss', \n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True,\n",
    "#                              mode='auto')\n",
    "early = EarlyStopping(monitor=\"val_acc\",\n",
    "                      mode=\"max\",\n",
    "                      patience=4)\n",
    "callbacks_list = [checkpoint,early] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06f8f7c9-052a-4321-9c0c-7a15d8913694",
    "_kg_hide-input": true,
    "_uuid": "4ecebd77f6f853473fa797e1bff2e06ee28fb012"
   },
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN, \n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps =STEP_SIZE_VALID ,\n",
    "                    epochs=epochs,\n",
    "                   callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "score = model.evaluate_generator(generator=valid_generator,\n",
    "steps=STEP_SIZE_VALID)\n",
    "print(\"Accuracy:\",score[1])\n",
    "print(\"Loss    :\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da1e27aa-67c0-4edd-b1fd-aeab841c7acd",
    "_uuid": "237840ee188c12133f4cc02b1bf69078da4c2259"
   },
   "source": [
    "\n",
    "\\0\n",
    "44# Run the validation data\n",
    "Here we run the validation data with minimal augmentation to see how well it performs and calculate a few stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7013ac7-abe2-4086-a68d-fe8721d48536",
    "_uuid": "0e01cf42088ff54a28ff8601da5d1f3b90674e17"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "out_dir = \"./\"\n",
    "model.load_weights(os.path.join(out_dir,file_path)) # load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_values = history.history['loss']\n",
    "validation_loss_values = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(training_loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, training_loss_values, label='Training Loss')\n",
    "plt.plot(validation_loss_values, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add test if available\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "valid_generator.reset()\n",
    "pred=model.predict_generator(valid_generator,steps=STEP_SIZE_validate,verbose=1)\n",
    "print(pred)\n",
    "y_true = valid_generator.classes\n",
    "y_pred =list(np.argmax([pred > 0.5],axis=-1).flatten()) \n",
    "\n",
    "print(\"kk\",np.shape(y_true))\n",
    "print(\"gg\",np.shape(y_pred))\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6f20581-e7d2-4d16-8856-5083da1b1e67",
    "_uuid": "28c832f58bdbeb515562d3a179c82a68c59964f6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true,y_pred ))\n",
    "# plt.matshow(confusion_matrix(y_true,y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06226ae1-c4c8-4203-92f7-aba5d4eee125",
    "_uuid": "9b8c9a042cbb9bfff8022d98340abaf3168a5f4d"
   },
   "source": [
    "# Make an ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "815f3422-7008-45d6-a2b5-4332097cb1be",
    "_uuid": "be0dcccaba11859b4fd003d353feb6dc5bc5fe94"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_true,y_pred )\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.plot(fpr, tpr, 'r.', label = 'MobileNet (AUC:%2.2f)' % roc_auc_score(y_pred, y_true))\n",
    "ax1.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "902a7ea3-4431-459a-9e20-958af56ce394",
    "_uuid": "dddf5a6661d2dc6f872744a929fb1196d4a78ab8"
   },
   "outputs": [],
   "source": [
    "# clean up the virtual directories\n",
    "import shutil\n",
    "for c_dir in glob('v_*'):\n",
    "    shutil.rmtree(c_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9147cb9b-c35c-44b3-9479-9b4cc52c27e1",
    "_uuid": "7d98ccb2d2404df284eec9f7f2e221753fa09e69"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
